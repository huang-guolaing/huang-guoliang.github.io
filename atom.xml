<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小黄笔记本</title>
  
  <subtitle>xh-notes</subtitle>
  <link href="https://huang-guoliang.github.io/atom.xml" rel="self"/>
  
  <link href="https://huang-guoliang.github.io/"/>
  <updated>2022-01-19T09:26:33.643Z</updated>
  <id>https://huang-guoliang.github.io/</id>
  
  <author>
    <name>Huang Guoliang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>分子的机器学习描述符</title>
    <link href="https://huang-guoliang.github.io/posts/68090c70/"/>
    <id>https://huang-guoliang.github.io/posts/68090c70/</id>
    <published>2022-01-19T00:49:44.000Z</published>
    <updated>2022-01-19T09:26:33.643Z</updated>
    
    <content type="html"><![CDATA[<p>文章链接：<a href="https://chemintelligence.com/blog/machine-learning-descriptors-molecules">Machine learning descriptors for molecules</a></p><!-- toc --><ul><li><a href="#适用于机器学习的描述符有哪些特点">适用于机器学习的描述符有哪些特点？</a></li><li><a href="#描述符有哪些类型">描述符有哪些类型？</a></li><li><a href="#如何选择描述符组合">如何选择描述符(组合)？</a></li><li><a href="#总结">总结</a></li><li><a href="#参考资料">参考资料</a></li></ul><!-- tocstop --><p>在预测分子性质时，分子结构在被用来训练机器学习模型之前被转换成描述符(descriptors)。</p><p><img src="workflow.jpg" alt="基于机器学习的分子性能预测的典型工作流程&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;"></p><p>本文的目的是概述分子描述符，并讨论三个主要问题:</p><h3><span id="适用于机器学习的描述符有哪些特点">适用于机器学习的描述符有哪些特点？</span></h3><p>选用一个满足以下三个标准的描述符来编码你的分子：</p><ol><li>描述符应与将要预测的分子性质有较高的相关性；</li><li>对应不同的分子结构，描述符应有有所差异；</li><li>根据分子大小选用合适的描述符(不是所有的描述符都适合所有大小的分子)。</li></ol><p>针对具体的机器学习任务，描述符还需要遵循其他一些标准，例如：</p><ul><li>能区分同分异构体；</li><li>可解码(从描述符返回到分子结构)；</li><li>数据量与描述符的维度(通常，数据集中的分子数量应远大于描述符的维数)。</li></ul><h3><span id="描述符有哪些类型">描述符有哪些类型？</span></h3><p>分子描述符分为两类：实验性的描述符和理论性的描述符。</p><ul><li><strong><em>实验性的描述符(Experimental)</em></strong>：<strong>实验测量或理论计算</strong>得到的物理化学性质。</li><li><strong><em>理论性的描述符(Theoretical)</em></strong>：来自于<strong>分子的符号表示</strong>。根据”维度“又可分为以下五类:<ul><li><strong><em>0维(0D)描述符</em></strong>：<strong>不提供</strong>任何有关<strong>分子结构或原子连通性信息</strong>的分子描述符。<br>例如，原子数、键数或分子量都是0D描述符。它们的优点是很容易获得，但要与其他描述符组合使用；</li><li><strong><em>1维(1D)描述符</em></strong>：由<strong>一组子结构</strong>(如官能团)<strong>计算</strong>得到的描述符。<br>其优点也是容易获得。其中，分子指纹就是一类最常见的1D描述符。</li><li><strong><em>2维(2D)描述符</em></strong>：通过分子的<strong>图表示(graph representation)</strong>获得分子<strong>拓扑信息</strong>的描述符。<br>典型的2D描述符是邻接矩阵(Adjacency matrix)，库仑矩阵(Coulomb matrix)和距离矩阵(Distance matrix)。<br>由于2D描述符对分子的结构特征(大小、形状和对称性)很敏感，因此它们是常用的一类描述符。</li><li><strong><em>3维(3D)描述符</em></strong>：提供有关分子原子空间<strong>坐标信息</strong>的几何描述符。<br>最著名的3D描述符是分子矩阵(Molecular matrix)和3D-MoRSE描述符。<br>在分子矩阵的情况下，这类描述符提供了大量关于分子的信息，并且具有区分异构分子的优势。<br>然而，由于几何描述符的复杂性，其计算十分耗时。</li><li><strong><em>4维(4D)描述符</em></strong>：也被称为“基于<strong>网格</strong>的描述符”。这类描述符除了分子几何外，还引入了第四维空间。<br>这个新维度通常表征分子与受体活性位点之间的相互作用或分子的多重构象状态。<br>常用的4D描述符有CoMFA和GRID。<br>4D描述符的一个优点是，它们提供了比其他描述符更多的信息，并且总是能够为结构不同的分子生成不同的值。<br>然而，就像3D描述符一样，4D描述符因其高复杂性而难以获取。</li></ul></li></ul><p><img src="theoretical_descriptors.bmp" alt="图示五类理论性的描述符(以布洛芬为例)&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;"></p><h3><span id="如何选择描述符组合">如何选择描述符(组合)？</span></h3><ul><li>从海量描述符中选择合适的描述符(组合)是一项非常困难的任务。</li><li>主要有两种选择策略：穷举搜索和优化算法。<ul><li><strong><em>穷举搜索(Exhaustive search)</em></strong>，也就是<strong>全子集</strong>模型(All Subset Model, ASM)。<br>N个描述符就有N<sup>2-1</sup>种组合。<br>此策略理论上能找到最优的描述符组合，但描述符数量过大时极为消耗算力，<br>比较适合只考虑少量描述符的情况。</li><li><strong><em>优化算法(Optimization algorithms)</em></strong>，是通过<strong>迭代</strong>方法找出能使预测模型结果最优的描述符组合。<br>比较常用的算法有进化规划(evolutionary programming，EP)，<br>蚁群优化(ant colony optimization，ACO)，<br>顺序查找(sequential search，SS)和遗传算法(genetic algorithms，GAs)。<br>一般的优化流程如下图所示：</li></ul></li></ul><div id="flowchart-0" class="flow-chart"></div><h3><span id="总结">总结</span></h3><ul><li>分子用描述符表示后，可作为机器学习模型的特征输入。</li><li>描述符的选择很重要，因为它对模型的预测性能有很大的影响。</li><li>在选择描述符时，有四个关注点：<ul><li>描述符与预测性质之间的相关性</li><li>描述符为结构不同的分子生成不同值的能力</li><li>描述符的维数</li><li>可用的数据量</li></ul></li><li>描述符不能完全描述分子的结构复杂性，可通过使用高维描述符或多个描述符部分地解决。</li><li>使用高维描述符或描述符组合会增加模型的复杂度而降低算法的性能。</li></ul><h3><span id="参考资料">参考资料</span></h3><div><script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.7/raphael.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.6.5/flowchart.min.js"></script><textarea id="flowchart-0-code" style="display: none">st=>start: 开始优化op1=>operation: 候选的描述符集合op2=>operation: 描述符子集cond=>condition: 预测模型评估e=>end: 最优的描述符子集    st->op1->op2(right)->condcond(no)->op1cond(yes)->e</textarea><textarea id="flowchart-0-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;"><a href="https://www.sciencedirect.com/science/article/pii/S0010465519303042">DScribe: Library of descriptors for machine learning in materials science</a></span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;"><a href="https://link.springer.com/protocol/10.1007/978-1-4939-7899-1_1">Molecular descriptors for structure–activity applications: a hands-on approach</a></span><a href="#fnref:2" rev="footnote"> ↩</a></li></ol></div></div></div>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;文章链接：&lt;a href=&quot;https://chemintelligence.com/blog/machine-learning-descriptors-molecules&quot;&gt;Machine learning descriptors for molecules&lt;/a&gt;&lt;/p</summary>
      
    
    
    
    <category term="Cheminformatics" scheme="https://huang-guoliang.github.io/categories/Cheminformatics/"/>
    
    
  </entry>
  
  <entry>
    <title>seaborn 绘图函数概述</title>
    <link href="https://huang-guoliang.github.io/posts/bc466d5/"/>
    <id>https://huang-guoliang.github.io/posts/bc466d5/</id>
    <published>2022-01-18T07:26:43.000Z</published>
    <updated>2022-01-18T08:52:19.272Z</updated>
    
    
    
    
    <category term="Tools" scheme="https://huang-guoliang.github.io/categories/Tools/"/>
    
    <category term="seaborn" scheme="https://huang-guoliang.github.io/categories/Tools/seaborn/"/>
    
    
  </entry>
  
  <entry>
    <title>《深度学习在分子与材料中的应用》导览</title>
    <link href="https://huang-guoliang.github.io/posts/f25b25e8/"/>
    <id>https://huang-guoliang.github.io/posts/f25b25e8/</id>
    <published>2022-01-18T06:19:04.000Z</published>
    <updated>2022-01-19T00:55:57.579Z</updated>
    
    
    
    
    <category term="Cheminformatics" scheme="https://huang-guoliang.github.io/categories/Cheminformatics/"/>
    
    <category term="dl4mm" scheme="https://huang-guoliang.github.io/categories/Cheminformatics/dl4mm/"/>
    
    
  </entry>
  
  <entry>
    <title>seaborn 教程导览</title>
    <link href="https://huang-guoliang.github.io/posts/a1871603/"/>
    <id>https://huang-guoliang.github.io/posts/a1871603/</id>
    <published>2022-01-18T02:21:56.000Z</published>
    <updated>2022-01-18T09:06:44.339Z</updated>
    
    <content type="html"><![CDATA[<!-- toc --><ul><li><a href="#教程目录">教程目录</a></li><li><a href="#安装-seaborn">安装 seaborn</a></li><li><a href="#初试-seaborn">初试 seaborn</a></li></ul><!-- tocstop --><blockquote><p><a href="https://seaborn.pydata.org">Seaborn</a> 是一个用 Python 制作统计图形的库。<br>它构建在 matplotlib 之上，并与 pandas 数据结构紧密集成。<br>它为绘制出吸引注意且信息丰富的统计图形提供了高级接口。</p></blockquote><h3><span id="教程目录">教程目录</span></h3><ul><li>API overview<ul><li><a href="../bc466d5">Overview of seaborn plotting functions</a></li><li><a href>Data structures accepted by seaborn</a></li></ul></li><li>Plotting functions<ul><li><a href>Visualizing statistical relationships</a></li><li><a href>Visualizing distributions of data</a></li><li><a href>Plotting with categorical data</a></li><li><a href>Visualizing regression models</a></li></ul></li><li>Multi-plot grids<ul><li><a href>Building structured multi-plot grids</a></li></ul></li><li>Plot aesthetics<ul><li><a href>Controlling figure aesthetics</a></li><li><a href>Choosing color palettes</a></li></ul></li></ul><h3><span id="安装-seaborn">安装 seaborn</span></h3><p>通过 PyPI 或 Anaconda 直接安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pip 安装</span></span><br><span class="line">pip install seaborn</span><br><span class="line"><span class="comment"># 或 conda 安装</span></span><br><span class="line">conda install seaborn</span><br></pre></td></tr></table></figure><h3><span id="初试-seaborn">初试 seaborn</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入 seaborn 库</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 载入 seaborn 自带的示例数据，</span></span><br><span class="line"><span class="comment"># 是 pandas 的 DataFrame 格式</span></span><br><span class="line">df = sns.load_dataset(<span class="string">&quot;penguins&quot;</span>)</span><br><span class="line"><span class="comment"># 如果是在 Jupyter Notebook 上运行，</span></span><br><span class="line"><span class="comment"># 可以直接显示出图片</span></span><br><span class="line">plot = sns.pairplot(data=df, hue=<span class="string">&quot;species&quot;</span>)</span><br><span class="line"><span class="comment"># 保存图片</span></span><br><span class="line">plot.figure.savefig(<span class="string">&quot;out.png&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在非 Jupyter Notebook 环境中，在窗口中</span></span><br><span class="line"><span class="comment"># 显示图片需要 matplotlib 的帮助</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>轻松绘制出漂亮的图表：</p><p><img src="seaborn_quick_start.png" alt="seaborn 绘图示例"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;!-- toc --&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#教程目录&quot;&gt;教程目录&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#安装-seaborn&quot;&gt;安装 seaborn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#初试-seaborn&quot;&gt;初试 seaborn&lt;/a&gt;&lt;/</summary>
      
    
    
    
    <category term="Tools" scheme="https://huang-guoliang.github.io/categories/Tools/"/>
    
    <category term="seaborn" scheme="https://huang-guoliang.github.io/categories/Tools/seaborn/"/>
    
    
    <category term="seaborn" scheme="https://huang-guoliang.github.io/tags/seaborn/"/>
    
  </entry>
  
  <entry>
    <title>《赤裸的统计学》第2章</title>
    <link href="https://huang-guoliang.github.io/posts/dac470bb/"/>
    <id>https://huang-guoliang.github.io/posts/dac470bb/</id>
    <published>2022-01-17T06:14:39.000Z</published>
    <updated>2022-01-19T00:55:26.152Z</updated>
    
    <content type="html"><![CDATA[<h2><span id="chapter-2-descriptive-statistics-who-was-the-best-baseball-player-of-all-time">CHAPTER 2. Descriptive Statistics: Who was the best baseball player of all time?</span></h2><ul><li>要点：<ul><li>平均数容易受到远离[中心区域的“异常值”的干扰而出现失真。</li><li>标准差用于衡量数据相对于平均值的分散程度。</li></ul></li></ul><style>  .article-entry table { width: 50%; }  table th { width: 30px; }</style><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">0</th><th style="text-align:center">1</th><th style="text-align:center">2</th><th style="text-align:center">3</th><th style="text-align:center">4</th><th style="text-align:center">5</th><th style="text-align:center">6</th><th style="text-align:center">7</th><th style="text-align:center">8</th><th style="text-align:center">9</th><th style="text-align:center">&gt;10</th></tr></thead><tbody><tr><td style="text-align:center">competitor</td><td style="text-align:center">12</td><td style="text-align:center">14</td><td style="text-align:center">36</td><td style="text-align:center">13</td><td style="text-align:center">8</td><td style="text-align:center">6</td><td style="text-align:center">5</td><td style="text-align:center">3</td><td style="text-align:center">0</td><td style="text-align:center">2</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">your</td><td style="text-align:center">25</td><td style="text-align:center">31</td><td style="text-align:center">9</td><td style="text-align:center">4</td><td style="text-align:center">3</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">26</td></tr></tbody></table></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">compet = [<span class="number">12</span>, <span class="number">14</span>, <span class="number">36</span>, <span class="number">13</span>, <span class="number">8</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>]</span><br><span class="line">your = [<span class="number">25</span>, <span class="number">31</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">26</span>]</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2&gt;&lt;span id=&quot;chapter-2-descriptive-statistics-who-was-the-best-baseball-player-of-all-time&quot;&gt;CHAPTER 2. Descriptive Statistics: Who was the </summary>
      
    
    
    
    <category term="Mathematics" scheme="https://huang-guoliang.github.io/categories/Mathematics/"/>
    
    <category term="Statistics" scheme="https://huang-guoliang.github.io/categories/Mathematics/Statistics/"/>
    
    <category term="naked-stats" scheme="https://huang-guoliang.github.io/categories/Mathematics/Statistics/naked-stats/"/>
    
    
    <category term="Stats" scheme="https://huang-guoliang.github.io/tags/Stats/"/>
    
  </entry>
  
  <entry>
    <title>《赤裸的统计学》第1章</title>
    <link href="https://huang-guoliang.github.io/posts/e1f2a54d/"/>
    <id>https://huang-guoliang.github.io/posts/e1f2a54d/</id>
    <published>2022-01-17T02:52:26.000Z</published>
    <updated>2022-01-19T00:55:12.816Z</updated>
    
    
    
    
    <category term="Mathematics" scheme="https://huang-guoliang.github.io/categories/Mathematics/"/>
    
    <category term="Statistics" scheme="https://huang-guoliang.github.io/categories/Mathematics/Statistics/"/>
    
    <category term="naked-stats" scheme="https://huang-guoliang.github.io/categories/Mathematics/Statistics/naked-stats/"/>
    
    
    <category term="Stats" scheme="https://huang-guoliang.github.io/tags/Stats/"/>
    
  </entry>
  
  <entry>
    <title>《赤裸的统计学》目录</title>
    <link href="https://huang-guoliang.github.io/posts/54daf226/"/>
    <id>https://huang-guoliang.github.io/posts/54daf226/</id>
    <published>2022-01-17T02:42:23.000Z</published>
    <updated>2022-01-19T00:54:59.563Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>英文原版：<a href="https://book.douban.com/subject/19941764/">Naked Statistics</a><br>中文译版：<a href="https://book.douban.com/subject/25717380/">赤裸的统计学</a></p></blockquote><ul><li><strong><em>Introduction: Why I hated calculus but love statistics</em></strong></li><li><a href="../e1f2a54d"><strong><em>Chapter 01. What’s the Point?</em></strong></a></li><li><a href><strong><em>Chapter 02. Descriptive Statistics</em></strong></a></li><li><a href><strong><em>Chapter 03. Deceptive Description</em></strong></a></li><li><a href><strong><em>Chapter 04. Correlation</em></strong></a></li><li><a href><strong><em>Chapter 05. Basic Probability</em></strong></a></li><li><a href><strong><em>Chapter 05½. The Monty Hall Problem</em></strong></a></li><li><a href><strong><em>Chapter 06. Probems with Probaility</em></strong></a></li><li><a href><strong><em>Chapter 07. The Importance of Data</em></strong></a></li><li><a href><strong><em>Chapter 08. The Central Limit Theorm</em></strong></a></li><li><a href><strong><em>Chapter 09. Inference</em></strong></a></li><li><a href><strong><em>Chapter 10. Polling</em></strong></a></li><li><a href><strong><em>Chapter 11. Regression Analysis</em></strong></a></li><li><a href><strong><em>Chapter 12. Common Regression Mistakes</em></strong></a></li><li><a href><strong><em>Chapter 13. Program Evaluations</em></strong></a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;英文原版：&lt;a href=&quot;https://book.douban.com/subject/19941764/&quot;&gt;Naked Statistics&lt;/a&gt;&lt;br&gt;中文译版：&lt;a href=&quot;https://book.douban.com/subje</summary>
      
    
    
    
    <category term="Mathematics" scheme="https://huang-guoliang.github.io/categories/Mathematics/"/>
    
    <category term="Statistics" scheme="https://huang-guoliang.github.io/categories/Mathematics/Statistics/"/>
    
    <category term="naked-stats" scheme="https://huang-guoliang.github.io/categories/Mathematics/Statistics/naked-stats/"/>
    
    
    <category term="Stats" scheme="https://huang-guoliang.github.io/tags/Stats/"/>
    
  </entry>
  
  <entry>
    <title>——欢迎光临我的博客——</title>
    <link href="https://huang-guoliang.github.io/posts/55bc8bfb/"/>
    <id>https://huang-guoliang.github.io/posts/55bc8bfb/</id>
    <published>2022-01-15T08:18:40.000Z</published>
    <updated>2022-01-19T09:23:28.037Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>我是 <del>老黄</del> 小黄，一名本硕 光学专业 在 化工行业 打滚的 IT 工程师。<br>现在主攻 机器学习 和 化学信息学。<br>给我发信息：xh-notes@foxmail.com</p></blockquote><p><strong><em>课程：</em></strong></p><ul><li><strong><em>Dive into Deep Learning</em></strong>　<a href="http://www.d2l.ai/">[课程地址]</a> <a href="https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358497">[视频地址]</a> <a href>[我的笔记]</a></li></ul><p><strong><em>教程：</em></strong></p><ul><li><strong><em>Seaborn Tutorial</em></strong>　<a href="posts/a1871603">[我的笔记]</a></li></ul><p><strong><em>书单：</em></strong></p><ul><li><strong><em>Deep Learning for Molecules and Materials; Andrew D. White; 2021.　</em></strong><a href="https://dmol.pub">[在线阅读]</a> <a href="posts/f25b25e8">[我的笔记]</a></li><li><strong><em>Deep Learning from Scratch; Seth Weidman; O’Reilly Media, Inc.; 2019.</em></strong>　<a href>[我的笔记]</a></li><li><strong><em>Naked Statistics; Charles Wheelan; W. W. Norton &amp; Company, Inc.; 2013.</em></strong>　<a href="posts/54daf226">[我的笔记]</a></li></ul><p><strong><em>文章：</em></strong></p><ul><li><strong><em>Machine learning descriptors for molecules; chemintelligence.com; 2021.</em></strong>　<a href="posts/68090c70">[我的笔记]</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;我是 &lt;del&gt;老黄&lt;/del&gt; 小黄，一名本硕 光学专业 在 化工行业 打滚的 IT 工程师。&lt;br&gt;现在主攻 机器学习 和 化学信息学。&lt;br&gt;给我发信息：xh-notes@foxmail.com&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;s</summary>
      
    
    
    
    
  </entry>
  
</feed>
